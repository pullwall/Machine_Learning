{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7482ccbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12217770821279003764\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5726273536\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12805322924908280736\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:2b:00.0, compute capability: 8.6\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "599fe44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Windows\\\\system32'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "forced-partition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id          img_path                 artist\n",
      "0   0  ./train/0000.jpg        Diego Velazquez\n",
      "1   1  ./train/0001.jpg       Vincent van Gogh\n",
      "2   2  ./train/0002.jpg           Claude Monet\n",
      "3   3  ./train/0003.jpg            Edgar Degas\n",
      "4   4  ./train/0004.jpg       Hieronymus Bosch\n",
      "5   5  ./train/0005.jpg  Pierre-Auguste Renoir\n",
      "6   6  ./train/0006.jpg          Rene Magritte\n",
      "7   7  ./train/0007.jpg          Rene Magritte\n",
      "8   8  ./train/0008.jpg           Michelangelo\n",
      "9   9  ./train/0009.jpg      Peter Paul Rubens\n",
      "[ 9 48  7 10 24]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Diego Velazquez</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vincent van Gogh</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Claude Monet</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Edgar Degas</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hieronymus Bosch</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             artist  num\n",
       "0   Diego Velazquez    9\n",
       "1  Vincent van Gogh   48\n",
       "2      Claude Monet    7\n",
       "3       Edgar Degas   10\n",
       "4  Hieronymus Bosch   24"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albrecht Du rer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albrecht Du rer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albrecht Du rer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albrecht Du rer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albrecht Du rer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>William Turner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>William Turner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>William Turner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>William Turner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>William Turner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5911 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist\n",
       "num                 \n",
       "0    Albrecht Du rer\n",
       "0    Albrecht Du rer\n",
       "0    Albrecht Du rer\n",
       "0    Albrecht Du rer\n",
       "0    Albrecht Du rer\n",
       "..               ...\n",
       "49    William Turner\n",
       "49    William Turner\n",
       "49    William Turner\n",
       "49    William Turner\n",
       "49    William Turner\n",
       "\n",
       "[5911 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Albrecht Du rer', 1: 'Alfred Sisley', 2: 'Amedeo Modigliani', 3: 'Andrei Rublev', 4: 'Andy Warhol', 5: 'Camille Pissarro', 6: 'Caravaggio', 7: 'Claude Monet', 8: 'Diego Rivera', 9: 'Diego Velazquez', 10: 'Edgar Degas', 11: 'Edouard Manet', 12: 'Edvard Munch', 13: 'El Greco', 14: 'Eugene Delacroix', 15: 'Francisco Goya', 16: 'Frida Kahlo', 17: 'Georges Seurat', 18: 'Giotto di Bondone', 19: 'Gustav Klimt', 20: 'Gustave Courbet', 21: 'Henri Matisse', 22: 'Henri Rousseau', 23: 'Henri de Toulouse-Lautrec', 24: 'Hieronymus Bosch', 25: 'Jackson Pollock', 26: 'Jan van Eyck', 27: 'Joan Miro', 28: 'Kazimir Malevich', 29: 'Leonardo da Vinci', 30: 'Marc Chagall', 31: 'Michelangelo', 32: 'Mikhail Vrubel', 33: 'Pablo Picasso', 34: 'Paul Cezanne', 35: 'Paul Gauguin', 36: 'Paul Klee', 37: 'Peter Paul Rubens', 38: 'Pierre-Auguste Renoir', 39: 'Piet Mondrian', 40: 'Pieter Bruegel', 41: 'Raphael', 42: 'Rembrandt', 43: 'Rene Magritte', 44: 'Salvador Dali', 45: 'Sandro Botticelli', 46: 'Titian', 47: 'Vasiliy Kandinskiy', 48: 'Vincent van Gogh', 49: 'William Turner'}\n",
      "Number of posters for training:  5319\n",
      "Number of posters for validation:  592\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "def cutout(image, label, probability=0.5):\n",
    "    if np.random.rand() < probability:\n",
    "        h, w = image.shape[:2]\n",
    "        size = np.random.randint(w // 2)\n",
    "        x1 = np.random.randint(w)\n",
    "        y1 = np.random.randint(h)\n",
    "        x2 = np.clip(x1 + size, 0, w)\n",
    "        y2 = np.clip(y1 + size, 0, h)\n",
    "        image[y1:y2, x1:x2, :] = np.random.rand(y2 - y1, x2 - x1, 3)\n",
    "    return image, label\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "label_encoder = LabelEncoder()\n",
    "artist_df = df.copy()\n",
    "artist_train = label_encoder.fit_transform(df['artist'].values)\n",
    "print(artist_df.head(10))\n",
    "print(artist_train[:5])\n",
    "\n",
    "artist_df['num'] = artist_train\n",
    "artist_df = artist_df.drop('id', axis=1)\n",
    "artist_df = artist_df.drop('img_path', axis=1)\n",
    "display(artist_df.head())\n",
    "\n",
    "artist_df.set_index('num', inplace=True)\n",
    "artist_df = artist_df.sort_index()\n",
    "display(artist_df)\n",
    "\n",
    "artist_test_dic = artist_df['artist'].to_dict()\n",
    "print(artist_test_dic)\n",
    "\n",
    "# 데이터 노이즈 수정\n",
    "df.loc[df['id'] == 3896, 'artist'] = 'Titian'\n",
    "df.loc[df['id'] == 3986, 'artist'] = 'Alfred Sisley'\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df, df['artist'].values, test_size=0.1)\n",
    "print(\"Number of posters for training: \", len(X_train))\n",
    "print(\"Number of posters for validation: \", len(X_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7346e366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4788 validated image filenames belonging to 50 classes.\n",
      "Found 531 validated image filenames belonging to 50 classes.\n"
     ]
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', classes=pd.unique(y_train), y=y_train)\n",
    "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(244,244,3), input_tensor=None, pooling=None)\n",
    "\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "predictions = Dense(50, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "LearningRate = 1e-3\n",
    "\n",
    "model.compile(optimizer=SGD(learning_rate=LearningRate, momentum=0.9, nesterov=True), \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "CP = ModelCheckpoint(filepath='model/' +\n",
    "                     'GoogleNet-Sigmoid-{epoch:03d}-{loss:.4f}-{val_loss:.4f}.hdf5',\n",
    "                     monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=0.00005)\n",
    "CALLBACK = [CP, LR]\n",
    "\n",
    "\n",
    "DATAGEN_TRAIN = ImageDataGenerator(\n",
    "    rescale=1/255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    data_format=\"channels_last\",\n",
    "    validation_split=0.10,\n",
    ")\n",
    "\n",
    "\n",
    "TRAIN_GENERATOR = DATAGEN_TRAIN.flow_from_dataframe(\n",
    "    dataframe=X_train, x_col='img_path', y_col='artist',\n",
    "    target_size=(244, 244), \n",
    "    class_mode='categorical',\n",
    "    batch_size=32, shuffle=True,\n",
    "    subset=\"training\",\n",
    "    preprocessing_function=cutout,\n",
    ")\n",
    "\n",
    "VALID_GENERATOR = DATAGEN_TRAIN.flow_from_dataframe(\n",
    "    dataframe=X_train, x_col='img_path', y_col='artist',\n",
    "    target_size=(244, 244), \n",
    "    class_mode='categorical',\n",
    "    batch_size=32, shuffle=True,\n",
    "    subset=\"validation\",\n",
    "    preprocessing_function=cutout,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6006be2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Epoch 1/50\n",
      "150/150 [==============================] - 101s 627ms/step - loss: 4.9485 - acc: 0.2141 - val_loss: 3.4170 - val_acc: 0.1902\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.41698, saving model to model\\GoogleNet-Sigmoid-001-4.9485-3.4170.hdf5\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 58s 386ms/step - loss: 3.1190 - acc: 0.4221 - val_loss: 2.4680 - val_acc: 0.3597\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.41698 to 2.46800, saving model to model\\GoogleNet-Sigmoid-002-3.1190-2.4680.hdf5\n",
      "Epoch 3/50\n",
      "150/150 [==============================] - 56s 375ms/step - loss: 2.3080 - acc: 0.5384 - val_loss: 1.9842 - val_acc: 0.4595\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.46800 to 1.98421, saving model to model\\GoogleNet-Sigmoid-003-2.3080-1.9842.hdf5\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 57s 377ms/step - loss: 1.8603 - acc: 0.6113 - val_loss: 1.9788 - val_acc: 0.4878\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.98421 to 1.97882, saving model to model\\GoogleNet-Sigmoid-004-1.8603-1.9788.hdf5\n",
      "Epoch 5/50\n",
      "150/150 [==============================] - 57s 381ms/step - loss: 1.4035 - acc: 0.6788 - val_loss: 1.6837 - val_acc: 0.5235\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.97882 to 1.68368, saving model to model\\GoogleNet-Sigmoid-005-1.4035-1.6837.hdf5\n",
      "Epoch 6/50\n",
      "150/150 [==============================] - 56s 374ms/step - loss: 1.2178 - acc: 0.7155 - val_loss: 1.6924 - val_acc: 0.5499\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.68368\n",
      "Epoch 7/50\n",
      "150/150 [==============================] - 58s 385ms/step - loss: 1.0403 - acc: 0.7550 - val_loss: 1.3430 - val_acc: 0.6290\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.68368 to 1.34298, saving model to model\\GoogleNet-Sigmoid-007-1.0403-1.3430.hdf5\n",
      "Epoch 8/50\n",
      "150/150 [==============================] - 58s 385ms/step - loss: 0.8742 - acc: 0.7840 - val_loss: 1.5181 - val_acc: 0.5782\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.34298\n",
      "Epoch 9/50\n",
      "150/150 [==============================] - 58s 382ms/step - loss: 0.7193 - acc: 0.8137 - val_loss: 1.2925 - val_acc: 0.6460\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.34298 to 1.29253, saving model to model\\GoogleNet-Sigmoid-009-0.7193-1.2925.hdf5\n",
      "Epoch 10/50\n",
      "150/150 [==============================] - 57s 381ms/step - loss: 0.6372 - acc: 0.8302 - val_loss: 1.3491 - val_acc: 0.6422\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.29253\n",
      "Epoch 11/50\n",
      "150/150 [==============================] - 57s 376ms/step - loss: 0.5732 - acc: 0.8490 - val_loss: 1.4402 - val_acc: 0.6271\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.29253\n",
      "Epoch 12/50\n",
      "150/150 [==============================] - 57s 379ms/step - loss: 0.4919 - acc: 0.8659 - val_loss: 1.1996 - val_acc: 0.6780\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.29253 to 1.19961, saving model to model\\GoogleNet-Sigmoid-012-0.4919-1.1996.hdf5\n",
      "Epoch 13/50\n",
      "150/150 [==============================] - 57s 377ms/step - loss: 0.4432 - acc: 0.8789 - val_loss: 1.6906 - val_acc: 0.5970\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.19961\n",
      "Epoch 14/50\n",
      "150/150 [==============================] - 57s 377ms/step - loss: 0.4078 - acc: 0.8885 - val_loss: 1.3323 - val_acc: 0.6554\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.19961\n",
      "Epoch 15/50\n",
      "150/150 [==============================] - 57s 375ms/step - loss: 0.3274 - acc: 0.9091 - val_loss: 1.1761 - val_acc: 0.6761\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.19961 to 1.17609, saving model to model\\GoogleNet-Sigmoid-015-0.3274-1.1761.hdf5\n",
      "Epoch 16/50\n",
      "150/150 [==============================] - 57s 378ms/step - loss: 0.3206 - acc: 0.9094 - val_loss: 1.2489 - val_acc: 0.6685\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.17609\n",
      "Epoch 17/50\n",
      "150/150 [==============================] - 57s 378ms/step - loss: 0.3083 - acc: 0.9104 - val_loss: 1.6838 - val_acc: 0.6026\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.17609\n",
      "Epoch 18/50\n",
      "150/150 [==============================] - 57s 378ms/step - loss: 0.3022 - acc: 0.9140 - val_loss: 1.2390 - val_acc: 0.6723\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.17609\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 19/50\n",
      "150/150 [==============================] - 57s 377ms/step - loss: 0.2226 - acc: 0.9348 - val_loss: 1.0956 - val_acc: 0.7081\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.17609 to 1.09559, saving model to model\\GoogleNet-Sigmoid-019-0.2226-1.0956.hdf5\n",
      "Epoch 20/50\n",
      "150/150 [==============================] - 59s 390ms/step - loss: 0.1868 - acc: 0.9432 - val_loss: 1.1377 - val_acc: 0.7024\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.09559\n",
      "Epoch 21/50\n",
      "150/150 [==============================] - 61s 408ms/step - loss: 0.1611 - acc: 0.9486 - val_loss: 1.0642 - val_acc: 0.7213\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.09559 to 1.06416, saving model to model\\GoogleNet-Sigmoid-021-0.1611-1.0642.hdf5\n",
      "Epoch 22/50\n",
      "150/150 [==============================] - 61s 407ms/step - loss: 0.1553 - acc: 0.9559 - val_loss: 1.0715 - val_acc: 0.7232\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.06416\n",
      "Epoch 23/50\n",
      "150/150 [==============================] - 61s 405ms/step - loss: 0.1539 - acc: 0.9555 - val_loss: 1.0388 - val_acc: 0.7307\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.06416 to 1.03883, saving model to model\\GoogleNet-Sigmoid-023-0.1539-1.0388.hdf5\n",
      "Epoch 24/50\n",
      "150/150 [==============================] - 61s 405ms/step - loss: 0.1377 - acc: 0.9574 - val_loss: 1.0931 - val_acc: 0.7062\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.03883\n",
      "Epoch 25/50\n",
      "150/150 [==============================] - 61s 406ms/step - loss: 0.1336 - acc: 0.9597 - val_loss: 1.0905 - val_acc: 0.7156\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.03883\n",
      "Epoch 26/50\n",
      "150/150 [==============================] - 61s 405ms/step - loss: 0.1214 - acc: 0.9662 - val_loss: 1.1315 - val_acc: 0.7288\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.03883\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 27/50\n",
      "150/150 [==============================] - 61s 406ms/step - loss: 0.1162 - acc: 0.9662 - val_loss: 1.0409 - val_acc: 0.7250\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.03883\n",
      "Epoch 28/50\n",
      "150/150 [==============================] - 60s 398ms/step - loss: 0.1042 - acc: 0.9724 - val_loss: 1.0384 - val_acc: 0.7156\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.03883 to 1.03843, saving model to model\\GoogleNet-Sigmoid-028-0.1042-1.0384.hdf5\n",
      "Epoch 29/50\n",
      "150/150 [==============================] - 62s 410ms/step - loss: 0.1097 - acc: 0.9672 - val_loss: 1.0449 - val_acc: 0.7232\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.03843\n",
      "Epoch 30/50\n",
      "150/150 [==============================] - 62s 409ms/step - loss: 0.1094 - acc: 0.9701 - val_loss: 1.0298 - val_acc: 0.7269\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.03843 to 1.02977, saving model to model\\GoogleNet-Sigmoid-030-0.1094-1.0298.hdf5\n",
      "Epoch 31/50\n",
      "150/150 [==============================] - 60s 395ms/step - loss: 0.1073 - acc: 0.9687 - val_loss: 1.0428 - val_acc: 0.7326\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.02977\n",
      "Epoch 32/50\n",
      "150/150 [==============================] - 57s 378ms/step - loss: 0.0994 - acc: 0.9714 - val_loss: 1.0457 - val_acc: 0.7156\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.02977\n",
      "Epoch 33/50\n",
      "150/150 [==============================] - 56s 373ms/step - loss: 0.0929 - acc: 0.9741 - val_loss: 0.9853 - val_acc: 0.7213\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.02977 to 0.98533, saving model to model\\GoogleNet-Sigmoid-033-0.0929-0.9853.hdf5\n",
      "Epoch 34/50\n",
      "150/150 [==============================] - 56s 372ms/step - loss: 0.0964 - acc: 0.9724 - val_loss: 0.9450 - val_acc: 0.7514\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.98533 to 0.94504, saving model to model\\GoogleNet-Sigmoid-034-0.0964-0.9450.hdf5\n",
      "Epoch 35/50\n",
      "150/150 [==============================] - 56s 375ms/step - loss: 0.0887 - acc: 0.9741 - val_loss: 1.0071 - val_acc: 0.7401\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.94504\n",
      "Epoch 36/50\n",
      "150/150 [==============================] - 56s 373ms/step - loss: 0.0869 - acc: 0.9758 - val_loss: 1.0542 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.94504\n",
      "Epoch 37/50\n",
      "150/150 [==============================] - 56s 374ms/step - loss: 0.0921 - acc: 0.9741 - val_loss: 0.9993 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.94504\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 38/50\n",
      "150/150 [==============================] - 56s 370ms/step - loss: 0.0950 - acc: 0.9716 - val_loss: 1.0278 - val_acc: 0.7420\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.94504\n",
      "Epoch 39/50\n",
      "150/150 [==============================] - 56s 372ms/step - loss: 0.0805 - acc: 0.9770 - val_loss: 1.0389 - val_acc: 0.7100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.94504\n",
      "Epoch 40/50\n",
      "150/150 [==============================] - 60s 399ms/step - loss: 0.0892 - acc: 0.9735 - val_loss: 1.0265 - val_acc: 0.7232\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.94504\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 41/50\n",
      "150/150 [==============================] - 57s 380ms/step - loss: 0.0797 - acc: 0.9779 - val_loss: 0.9937 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.94504\n",
      "Epoch 42/50\n",
      "150/150 [==============================] - 56s 374ms/step - loss: 0.0788 - acc: 0.9787 - val_loss: 1.0079 - val_acc: 0.7401\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.94504\n",
      "Epoch 43/50\n",
      "150/150 [==============================] - 56s 370ms/step - loss: 0.0791 - acc: 0.9754 - val_loss: 1.0155 - val_acc: 0.7307\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.94504\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 5e-05.\n",
      "Epoch 44/50\n",
      "150/150 [==============================] - 56s 371ms/step - loss: 0.0870 - acc: 0.9770 - val_loss: 1.0028 - val_acc: 0.7458\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.94504\n",
      "Epoch 45/50\n",
      "150/150 [==============================] - 56s 372ms/step - loss: 0.0857 - acc: 0.9751 - val_loss: 1.0265 - val_acc: 0.7250\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.94504\n",
      "Epoch 46/50\n",
      "150/150 [==============================] - 55s 369ms/step - loss: 0.0782 - acc: 0.9785 - val_loss: 0.9702 - val_acc: 0.7533\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.94504\n",
      "Epoch 47/50\n",
      "150/150 [==============================] - 55s 366ms/step - loss: 0.0849 - acc: 0.9783 - val_loss: 1.0166 - val_acc: 0.7307\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.94504\n",
      "Epoch 48/50\n",
      "150/150 [==============================] - 55s 366ms/step - loss: 0.0744 - acc: 0.9787 - val_loss: 1.0558 - val_acc: 0.7476\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.94504\n",
      "Epoch 49/50\n",
      "150/150 [==============================] - 55s 367ms/step - loss: 0.0784 - acc: 0.9758 - val_loss: 1.0268 - val_acc: 0.7269\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.94504\n",
      "Epoch 50/50\n",
      "150/150 [==============================] - 56s 374ms/step - loss: 0.0721 - acc: 0.9814 - val_loss: 1.0382 - val_acc: 0.7175\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.94504\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    TRAIN_GENERATOR,\n",
    "    epochs=50,\n",
    "    callbacks=CALLBACK,\n",
    "    shuffle=True,\n",
    "    validation_data=VALID_GENERATOR,\n",
    "    class_weight=class_weights_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0413e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12670 validated image filenames.\n",
      "198/198 [==============================] - 135s 674ms/step\n"
     ]
    }
   ],
   "source": [
    "X_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "DATAGEN_TEST = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    data_format=\"channels_last\"\n",
    ")\n",
    "\n",
    "TEST_GENERATOR = DATAGEN_TEST.flow_from_dataframe(\n",
    "    dataframe=X_test,\n",
    "    x_col='img_path',\n",
    "    y_col=None,\n",
    "    target_size=(244, 244),\n",
    "    color_mode='rgb',\n",
    "    class_mode=None,\n",
    "    batch_size=64,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "TEST_Prediction = model.predict(TEST_GENERATOR, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "020d68fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_num = np.argmax(TEST_Prediction, axis=1)\n",
    "num_list = pd.DataFrame(artist_num, columns=['artist'])\n",
    "num_list.to_csv(\"ansRN50.csv\", index=False)\n",
    "df_ans = pd.read_csv(\"ansRN50.csv\")\n",
    "\n",
    "#df_ans(예측한 숫자가 담긴 파일)를 받아와서 처음에 만들었던 label_encoder 숫자를 보고 숫자를 작가로 바꾼다 \n",
    "artist_name = []\n",
    "for i in num_list['artist']:\n",
    "    artist_name.append(artist_test_dic[i])\n",
    "\n",
    "last_ans = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "last_ans.rename(columns={'artist':'artist_name'}, inplace=True)\n",
    "\n",
    "last_ans['artist'] = artist_name\n",
    "last_ans.drop('artist_name', axis=1, inplace=True)\n",
    "\n",
    "last_ans.to_csv(\"GoogleNet_50.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998570ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
